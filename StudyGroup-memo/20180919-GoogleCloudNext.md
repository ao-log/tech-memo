
# 基調講演

基調講演はあまりメモを取らなかったです・・・

### ダイアン グリーンさんとファーストリテイリング柳井さんとの対談にて

いかに最先端の技術を使って、早くやるか。

### 佐藤さん

AutoML Translation により、分野ごとに特化した学習モデルを作ることができる。専門分野でも、意味が通る翻訳をしてくれる。

# 脱 SSH 鍵管理！ GCP の Web ベース開発環境をユースケース別に徹底解説

Cloud Shell は開発者が使いやすい UI/UX を提供している。

### Cloud Shell

* 5 GB の永続領域
* Cloud SDK がビルトイン
* boost mode により、一時的なスペックアップが可能
* Web プレビュー
* コードエディタ
* IAM と OS のログインユーザを統合

鍵管理、運用負荷、セキュリティ面で楽になる。

### Cloud Console

* Google/G Suite アカウントでログイン
  * 2 段階認証
  * Titan Security key
* 監査ログを残せる

### ハンズオン環境の作り方

* ハンズオン用のプロジェクトを作る。
* 参加者が必要なのはブラウザだけ。
* Cloud Shell のチュートリアルを作ることができる。
  * Markdown で書ける
  * コマンドをシェルに貼り付けることもできる。
* Git リポジトリを Cloud Shell にクローンするボタンを作れる。

# ビジネス視点で考える現実世界の機械学習とデータサイエンス 〜AI をブラックボックスにしないデータ活用術〜

機械学習のメインは予測。その判断をどうするかはビジネス側のお仕事（機械学習がそこまでやってくれるわけではない）。

|項目|説明|
|---|---|
|統計分析|データの意味を理解する。これが機械学習の出発点。何が起きていたかを読み取る。|
|ストリーミング分析、ダッシュボード|今何が起きているかを理解できる。|
|機械学習|未来のデータ(予測データ)から今何をするべきかを判断する。|

これらは時刻が異なるだけで、同じ種類のデータ。

##### シナリオ

故障予測のシナリオで考える。

ストリームデータの分析。

* Pub/Sub から BigQuery に流し込む。
* DataLab 上から BigQuery に対してクエリを実行。
  * 時系列データのグラフ化（外れ値など、傾向を見る）
  * ヒストグラムで分布を見る
* DataStudio で可視化

未来予測の場合。

* BigQuery ML を使用する。

### ビジネスにおいて

データサイエンティストはビズネスエキスパート、データスペシャリスト、機械学習スペシャリストを繋ぎあわせる役割。

継続的な試行錯誤とモデルの再学習、ビジネスからのフィードバックのループが必要。

# Google Home アプリをサーバレスで実現！ピカチュウトーク開発の裏側をご紹介

### Actions on google

自分たちで開発したアプリで会話ができる。

* Actions SDK: 会話のパターンが少ない場合はこちらを使う
* Dialogflow: 自然でリッチな会話体験を可能にする IDE。このケースではこちらを選定。


### ピカチュウトーク

* 朝、夜は眠いらしい
* 10 万ボルトを連続して使うと疲れる

### 作成

1. スプレッドシートに台本
1. JavaScript で DiagFlow にインポート
1. DiagFlow に実装
1. シミュレータでテスト

Cloud Functions 内の Node.js がピカチュウ音声の再生要求を行う。  
親密度などは Cloud Datastore で管理。  
Cloud Storage からストリーミング再生。

### Intent

ありがとうに近しい言葉を登録しておくと、ありがとうに近い言葉が Intent に落ちてくる。
ローカライズは、単に翻訳ではなく、言語にあった表現に再設定する。

### まとめ

* VUI の設定はシンプルにした方が良い
* Intent の登録と改善が大変だが、DialogFlow で GUI で簡単にできる

# Kubernetes を使った継続的デリバリー 〜GCPにおけるベストプラクティス＆AmebaTV における取り組み〜

Source → Build/Test → Artifact storage → Deploy  
各工程の課題をどう解決していくか？

GCP だと Cloud Source Repositries → Cloud Build → Container Registry → GKE となる。以下のメリットがある

* 高速、安全：カナリア、Green-Blue などのデプロイ戦略を選べる
* フルマネージド
* リスクの低減：脆弱性スキャン、監査ログ

##### Cloud Build

* push をトリガーにビルドを実行。ビルドステップを yaml で定義
* GitHub とも連携可能
* KMS とも連携が取れる

##### Container Registry

* 脆弱性スキャンできる

### AmebaTV

広告はクラスタに合わせて配信内容を変えている。

2 つのリージョン。2 つの GKE クラスタ。
* ソースは GitHub。
* ビルドは drone.io で GKE 上に乗っている。
* コンテナレジストリは Cloud Registry。
* デプロイは Slack（基本的に ChatOps で対応している）。Kubernetes の manifest が pull Request で生成されるので、それをマージするとデプロイされる。
* モニタリングは Prometheus。Kubernetes との相性が良い。

##### 課題と展望

* 手動部分を自動化していきたい
* drone.io を Cloud Build に変えたい（ビルドがたまるとスケールアウトするのが難しい問題を解消したい）

# 徹底解説！Kubernetes ランタイムセキュリティ

Kubernetes について起こったインシデント。
インターネットにさらされており、特権の IAM キーや AWS のアクセスキーが含まれていた。暗号化マイニングに使われてしまった。

* インフラ面：　API、特権、認証情報を守る必要がある。バージョンアップ、パッチ適用が必要。
* ソフトウェア面：　パッチ適用。
* ランタイム：　DDoS、ノードの侵害、コンテナのエスケープ

### セキュリティ。VM、コンテナの違い。

|項目|VM|コンテナ|
|---|---|---|
|攻撃境界|ハイパーバイザーが強力な境界となる|最小限のホストOSで攻撃領域を限定する。|
|分離|すべて十分に分離されるわけではない|cgroup によって分離される。|
|root 権限|幅広いシステムコールにアクセス|アプリケーションの権限と共有リソースに対するアクセス制限|
|存続期間|長い|平均存続時間は短い。|

### コンテナ監視の設計

* ロギングする（もっと詳細な内容が必要）
* ポリシーを決める
  * アラート
  * 自動修復
* 事後のフォレンジック調査を可能にする

有用なツール

* ptrace, kprobes, tracepoints
* eBPF: カーネルの等さ
* XDP: ネットワークパケットをフィルタリング

そのままだとログの情報量が大きすぎるので、フィルタリングが必要。
管理用のコンテナで収集し、DBやストレージに蓄積していく。

インシデントへの対応方法

* アラートの送信
* コンテナの分離。新しいネットワークに移動
* コンテナの一時停止、再起動、終了

### 今からできること

* セキュリティ計画に組み込む
* 特定の状況の予行演習を実施

# 徹底解説、データレイクの構築と活用

### データレイクとは？

raw データの集まりのこと。
多くの目的に使用するために、一箇所に集めて格納する。

**特徴**

* データ処理と疎結合
* 複数の用途で利用できること

Hadoop はデータと処理が同じなので、データレイクではない。

**なぜ構築するのか**

事前作業、スキーマ設計が少なくて済む。
様々なツールで利用できるために、API で利用可能。
コスト効率も良い。

**組織構造がデータ構造に影響を与える**

システムを設計する組織は、その構造をそっくり真似た構造の設計を生み出してしまう。（コンウェイの法則）

普通の企業は部門ごとに分かれている。他の部門と統合しようとすると、異なる DWH を使用していたりするので、統合が難しい。データの保存先、期間、管理者、セキュリティ、レイテンシもバラバラだったりする。

データは資産ではなく、コストとして見られている。

こういった状況を解消するのが、データレイク。
一方で、DWH は目的がはっきりしている場合にはとてもよいが、スキーマ設計が必要なので手間がかかる。

### GCP でどのようなサービスが適しているのか

Cloud Storage がデータレイクとして適している。
DWH として使う場合は、BigQuery にインポートするのが定番。

**GCS**

コスト、可用性が 4 パターンあるので、シーンに応じて最適化できる。どのストレージクラスに対しても同じ API でミリ秒でアクセス可能（Cold Line であっても）。ファイルによって、ストレージクラスを変えることもできる。
グローバルな強い整合性。容量がスケールする。

**memo**

マルチリージョナルとリージョナルの違い。マルチリージョナルは、US, EU, ASIA の三つの単位。マルチリージョナルだと、複数リージョンに複製する。

東京には三つのゾーンがある。
リージョン間は海底ケーブルでつながっており、非常に広帯域、高速。

30day で Nier Line, 90day でCold Line,365day で削除のようなライフサイクルも組める。

* バッチ
  * gsutil
  * Storage Transfer service
  * distcp
* ストリーム
  * Pub/Sub


### どうやってデータを活用するか？

**Dataproc**

フルマネージドの Spark, Hadoop クラスタ。90 秒以内にクラスタが立ち上がる。サポートしているジョブは、Hadoop, Spark, Pig, Hive。

##### Tips

* HDFS を Cloud Storage に置き換える（Hadoop互換のコネクタがあるので対応できる）
* 複数のクラスタから同じデータを読めるので、データの複製はしなくて良い
* ユースケースにあった適切なサイズのクラスタ
* Cloud Datapeoc job を使用する。（後でトレース可能。ユーザアカウントの作成が不要）
* クラスタの作成と削除を頻繁に行う。

##### 最近の新機能

* カスタムイメージ（クラスタのセットアップ時間を短縮できる）
* ワークフロー（クラスタの作成から投入、結果回収、削除までをワークフローで定義できる）
* オートスケーリング（モニタリングして調整しなくても、自動で調整してくれる）

### BigQuery

* 圧縮されたカラムナストレージ
* テーブルはシャード単位でスケールするようになっている

ML API で非構造化データを半構造化データ(json)へ変換。これを BigQuery に突っ込むことで、分析できるようになる。

Federated Query でデータ分析。GCS 上のデータに対し、分析できる。

### 最後に

現状を分析するためにデータが必要。機械学習で未来を予測するのは、それからというステップになるのでは？

# DogRun - Kubernetes

（直前のパーティーでワインを飲んだせいで、うとうとしてて内容が頭に入りませんでした。すみません。。）

Borg の改善点を書き換えたのが、Omega。ただし、実際に置き換わることはなかった。とはいえ、その知見が Kubernetes に活きている。C++ だと誰でも書けないが、Go だとある程度枯れているし入りやすい。

gVisor - isolation が課題だったのが動機。

Istio & Service Mesh - サービスメッシュとはスマートネットワークなんじゃない？ アプリケーションに組み込んでいたものをサービスメッシュ側で対応できるので、アプリケーションがよりシンプルになる。
